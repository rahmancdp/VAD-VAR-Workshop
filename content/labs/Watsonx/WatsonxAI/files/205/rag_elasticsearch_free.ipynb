{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Install and import dependecies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install langchain | tail -n 1\n",
                "%pip install -U langchain-community\n",
                "%pip install elasticsearch | tail -n 1\n",
                "%pip install langchain_elasticsearch | tail -n 1\n",
                "%pip install sentence_transformers | tail -n 1\n",
                "%pip install humanize | tail -n 1\n",
                "%pip install pandas | tail -n 1\n",
                "%pip install rouge_score | tail -n 1\n",
                "%pip install nltk | tail -n 1\n",
                "%pip install wget | tail -n 1\n",
                "%pip install ibm_watsonx_ai | tail -n 1\n",
                "%pip install \"pydantic==1.10.0\" | tail -n 1\n",
                "%pip install \"ibm-watson-machine-learning>=1.0.327\" | tail -n 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, getpass\n",
                "import pandas as pd\n",
                "import humanize\n",
                "import random\n",
                "from typing import Optional, Any, Iterable, List"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### watsonx API connection\n",
                "This cell defines the credentials required to work with watsonx API for Foundation\n",
                "Model inferencing.\n",
                "\n",
                "**Action:** Provide the IBM Cloud user API key. For details, see <a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\" rel=\"noopener no referrer\">documentation</a>."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "credentials = {\n",
                "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
                "    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n",
                "}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Defining the project id\n",
                "The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n",
                "\n",
                "**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    project_id = os.environ[\"PROJECT_ID\"]\n",
                "except KeyError:\n",
                "    project_id = input(\"Please enter your project_id (hit enter): \")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"data\"></a>\n",
                "## Data (test) loading"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Download the test dataset. This dataset is used to calculate the metrics score for selected model, defined prompts and parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import wget\n",
                "\n",
                "questions_test_filename = 'questions_test.csv'\n",
                "questions_train_filename = 'questions_train.csv'\n",
                "questions_test_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/questions_test.csv'\n",
                "questions_train_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/questions_train.csv'\n",
                "\n",
                "\n",
                "if not os.path.isfile(questions_test_filename): \n",
                "    wget.download(questions_test_url, out=questions_test_filename)\n",
                "\n",
                "\n",
                "if not os.path.isfile(questions_train_filename): \n",
                "    wget.download(questions_train_url, out=questions_train_filename)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "filename_test = './questions_test.csv'\n",
                "filename_train =  './questions_train.csv'\n",
                "\n",
                "test_data = pd.read_csv(filename_test)\n",
                "train_data = pd.read_csv(filename_train)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Inspect data sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Build up knowledge base\n",
                "\n",
                "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
                "\n",
                "We can generate dense vector representations using embedding models. In this notebook, we use <a href=\"https://www.sbert.net/\" target=\"_blank\" rel=\"noopener no referrer\">Sentence Transformers</a> <a href=\"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" target=\"_blank\" rel=\"noopener no referrer\">all-MiniLM-L6-v2</a> to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n",
                "\n",
                "A vector database is optimized for dense vector indexing and retrieval. This notebook uses <a href=\"https://python.langchain.com/docs/integrations/vectorstores/elasticsearch#basic-example\" target=\"_blank\" rel=\"noopener no referrer\">Elasticsearch</a>, a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The dataset we are using is already split into self-contained passages that can be ingested by Elasticsearch. \n",
                "\n",
                "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load knowledge base documents\n",
                "\n",
                "Load set of documents used further to build knowledge base. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "knowledge_base_dir = \"./knowledge_base\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "my_path = f\"{os.getcwd()}/knowledge_base\"\n",
                "if not os.path.isdir(my_path):\n",
                "   os.makedirs(my_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "documents_filename = 'knowledge_base/psgs.tsv'\n",
                "documents_url = 'https://raw.github.com/IBM/watson-machine-learning-samples/master/cloud/data/RAG/psgs.tsv'\n",
                "\n",
                "\n",
                "if not os.path.isfile(documents_filename): \n",
                "    wget.download(documents_url, out=documents_filename)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "documents = pd.read_csv(f\"{knowledge_base_dir}/psgs.tsv\", sep='\\t', header=0)\n",
                "documents['indextext'] = documents['title'].astype(str) + \"\\n\" + documents['text']\n",
                "documents = documents[:1000]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create an embedding function\n",
                "\n",
                "Note that you can feed a custom embedding function to be used by Elasticsearch. The performance of Elasticsearch may differ depending on the embedding model used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.embeddings import SentenceTransformerEmbeddings\n",
                "from langchain.embeddings.base import Embeddings\n",
                "\n",
                "emb_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"models\"></a>\n",
                "## Foundation Models on watsonx"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Defining model\n",
                "You need to specify `model_id` that will be used for inferencing:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
                "\n",
                "model_id = ModelTypes.FLAN_UL2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Defining the model parameters\n",
                "We need to provide a set of model parameters that will influence the result:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
                "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
                "\n",
                "parameters = {\n",
                "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
                "    GenParams.MIN_NEW_TOKENS: 1,\n",
                "    GenParams.MAX_NEW_TOKENS: 50\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize the `Model` class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ibm_watson_machine_learning.foundation_models import Model\n",
                "\n",
                "watsonx_granite = Model(\n",
                "    model_id=model_id.value,\n",
                "    credentials=credentials,\n",
                "    project_id=project_id,\n",
                "    params=parameters\n",
                ").to_langchain()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"elastic_conn\"></a>\n",
                "\n",
                "We'll use the Cloud ID to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
                "To find the password for the `elastic` user, go to https://cloud.elastic.co/deployments and select your deployment. Then on the left-hand sided menu select the `Security` settings.\n",
                "Click on the `Reset password` button and copy the generated password.\n",
                "\n",
                "\n",
                "The following cell retrieves the Elasticsearch Cloud ID and password for the `elastic` user from the environment if available and prompts you otherwise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
                "try:\n",
                "    es_cloud_id = os.environ[\"ELASTIC_CLOUD_ID\"]\n",
                "except KeyError:\n",
                "    es_cloud_id = input(\"Please enter your Elasticsearch Cloud ID (hit enter): \")\n",
                "\n",
                "\n",
                "try:\n",
                "    es_password = os.environ[\"ELASTIC_PASSWORD\"]\n",
                "except KeyError:\n",
                "    es_password = input(\"Please enter your Elasticsearch Deployment PASSWORD (password per Elasticsearch online deployment, hit enter): \")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"elasticsearchstore\"></a>\n",
                "## Set up ElasticsearchStore connector from Langchain\n",
                "\n",
                "\n",
                "We first create a regular Elasticsearch Python client connection. Then we pass it into LangChain's ElasticsearchStore wrapper together with the WatsonX model based embedding function.\n",
                "\n",
                "Consult the LangChain documentation For more information about <a href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html\" target=\"_blank\" rel=\"noopener no referrer\">ElasticsearchStore</a> connector."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_elasticsearch import ElasticsearchStore\n",
                "from elasticsearch import Elasticsearch\n",
                "\n",
                "# Create the client instance\n",
                "es_connection = Elasticsearch(\n",
                "    cloud_id=es_cloud_id,\n",
                "    basic_auth=(\"elastic\", es_password)\n",
                ")\n",
                "\n",
                "# Successful response!\n",
                "es_connection.info()\n",
                "\n",
                "\n",
                "knowledge_base = ElasticsearchStore(es_connection=es_connection,\n",
                "                                    index_name=\"test_index\",\n",
                "                                    embedding=emb_func,\n",
                "                                    strategy=ElasticsearchStore.ApproxRetrievalStrategy(),\n",
                "                                    distance_strategy=\"DOT_PRODUCT\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"elasticsearchstore_index\"></a>\n",
                "### Embed and index documents with Elasticsearch\n",
                "\n",
                "**Note: Could take several minutes if you don't have pre-built indices**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "if es_connection.indices.exists(index=\"test_index\"):\n",
                "    es_connection.indices.delete(index=\"test_index\")\n",
                "_ = knowledge_base.add_texts(texts=documents.indextext.tolist(),\n",
                "                             metadatas=[{'title': title, 'id': doc_id}\n",
                "                                for (title, doc_id) in\n",
                "                                zip(documents.title, documents.id)],  # filter on these!\n",
                "                             index_name=\"test_index\",\n",
                "                             ids=[str(i) for i in documents.id]  # unique for each doc\n",
                "                            )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's take a look in Elasticsearch what the LangChain wrapper has created. First we display the newly created index (\"tables\" in Elasticsearch are always called \"index\"). Note the field `vector` of type `dense_vector` with `dot_product` similarity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dict(es_connection.indices.get(index=\"test_index\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Verify the number of documents loaded into the Elasticsearch index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "doc_count = es_connection.count(index='test_index')[\"count\"]\n",
                "doc_count"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's retrieve a random document as a sample. Note the embedding in the vector field, that was generated with the WatsonX embedding model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dict(es_connection.get(index=\"test_index\", id=random.randint(0, len(documents)-1)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Display the total size and indexing time of the new index in Elasticsearch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "index_stats = es_connection.indices.stats(index=\"test_index\").get('_all').get('primaries')\n",
                "print(\"Index size:    \" + humanize.naturalsize(index_stats.get('store').get('size_in_bytes')))\n",
                "print(\"Indexing time: \" + humanize.precisedelta(index_stats.get('indexing').get('index_time_in_millis')/1000, minimum_unit='minutes'))\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a id=\"predict\"></a>\n",
                "## Generate a retrieval-augmented response to a question"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`RetrievalQA` is a chain to do question answering.\n",
                "\n",
                "**Hint:** To use Chain interface from LangChain with watsonx.ai models you must call `model.to_langchain()` method. \n",
                "\n",
                "It returns `WatsonxLLM` wrapper compatible with LangChain CustomLLM specification."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Select questions\n",
                "\n",
                "The prompts we will use to test the RAG flow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "questions_and_answers = {\n",
                "            'names of founding fathers of the united states?': \"Thomas Jefferson::James Madison::John Jay::George Washington::John Adams::Benjamin Franklin::Alexander Hamilton\",\n",
                "            'who played in the super bowl in 2013?': 'Baltimore Ravens::San Francisco 49ers',\n",
                "            'when did bucharest become the capital of romania?': '1862'\n",
                "}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retrieve relevant context\n",
                "\n",
                "Fetch paragraphs similar to the question"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.chains import RetrievalQA\n",
                "\n",
                "qa = RetrievalQA.from_chain_type(llm=watsonx_granite, chain_type=\"stuff\",verbose=True, retriever=knowledge_base.as_retriever(), return_source_documents=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "\n",
                "\n",
                "for question in questions_and_answers.keys():\n",
                "\n",
                "    result = qa.invoke({'query': question})\n",
                "\n",
                "    print(\"result: \", result)\n",
                "    results.append( result)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Get the set of chunks for one of the questions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for idx, result in enumerate(results):\n",
                "    print(\"=========\")\n",
                "    print(\"Question = \", result['query'])\n",
                "    print(\"Answer = \", result['result'])\n",
                "    print(\"Expected Answer(s) (may not be appear with exact wording in the dataset) = \", questions_and_answers[result['query']])\n",
                "    print(\"\\n\")\n",
                "    print(\"Source documents:\")\n",
                "    print(*(x.page_content for x in result['source_documents']), sep='\\n')\n",
                "    print(\"\\n\")\n",
                "    "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Copyright Â© 2023 IBM. This notebook and its source code are released under the terms of the MIT License."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "BIG-bench",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
